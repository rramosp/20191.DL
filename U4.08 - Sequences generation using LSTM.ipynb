{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling\n",
    "\n",
    "A recurrence Neural Network can be used as a Generative model once it was trained. Currently this is a common practice not only to study how well a model has learned a problem, but to learn more about the problem domain itself. In fact, this approach is being used for music generation and composition.\n",
    "\n",
    "The process of generation is explained in the picture below:\n",
    "\n",
    "<img src=\"Images/dinos3.png\" style=\"width:500;height:300px;\">\n",
    "<caption><center> **Figure **: In this picture, we assume the model is already trained. We pass in $x^{\\langle 1\\rangle} = \\vec{0}$ at the first time step, and have the network then sample one character at a time. </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1467,
     "status": "ok",
     "timestamp": 1555975727588,
     "user": {
      "displayName": "JULIAN DAVID ARIAS LONDOÑO",
      "photoUrl": "https://lh4.googleusercontent.com/-QOhj8seXZ4M/AAAAAAAAAAI/AAAAAAAAAKs/jFWlR3Fk460/s64/photo.jpg",
      "userId": "14990390101324121504"
     },
     "user_tz": 300
    },
    "id": "L124Iiv3dcSl",
    "outputId": "18d268d6-4d4e-418e-9e8a-daae981918eb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Masking\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM, CuDNNLSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2042,
     "status": "ok",
     "timestamp": 1555975730643,
     "user": {
      "displayName": "JULIAN DAVID ARIAS LONDOÑO",
      "photoUrl": "https://lh4.googleusercontent.com/-QOhj8seXZ4M/AAAAAAAAAAI/AAAAAAAAAKs/jFWlR3Fk460/s64/photo.jpg",
      "userId": "14990390101324121504"
     },
     "user_tz": 300
    },
    "id": "sCLzUHaydf0L",
    "outputId": "d506a656-6af5-48b8-b3b5-4f0a98e8096e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "77PUPiYEdkXx"
   },
   "outputs": [],
   "source": [
    "# load ascii text and covert to lowercase\n",
    "raw_text = nltk.corpus.gutenberg.raw('bible-kjv.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 377,
     "status": "ok",
     "timestamp": 1555975733415,
     "user": {
      "displayName": "JULIAN DAVID ARIAS LONDOÑO",
      "photoUrl": "https://lh4.googleusercontent.com/-QOhj8seXZ4M/AAAAAAAAAAI/AAAAAAAAAKs/jFWlR3Fk460/s64/photo.jpg",
      "userId": "14990390101324121504"
     },
     "user_tz": 300
    },
    "id": "PSxrzWNQdnwL",
    "outputId": "2951ff2e-d20e-4ca0-b028-cb57b33dde5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Genesis\\n\\n\\n1:1 In the beginning God created the heaven and the earth.\\n\\n1:2 And the earth was without form, and void; and darkness was upon\\nthe face of the deep. And the Spirit of God moved upon the face of the\\nwaters.\\n\\n1:3 And God said, Let there be light: and there was light.\\n\\n1:4 And God saw the light, that it was good: and God divided the light\\nfrom the darkness.\\n\\n1:5 And God called the light Day, and the darkness he called Night.\\nAnd the evening and the morning were the first day.\\n\\n1:6 And God said, Let there be a firmament in the midst of the waters,\\nand let it divide the waters from the waters.\\n\\n1:7 And God made the firmament, and divided the waters which were\\nunder the firmament from the waters which were above the firmament:\\nand it was so.\\n\\n1:8 And God called the firmament Heaven. And the evening and the\\nmorning were the second day.\\n\\n1:9 And God said, Let the waters under the heav'"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text[100:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t4hStmi5dpyb"
   },
   "outputs": [],
   "source": [
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1395
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1555975737585,
     "user": {
      "displayName": "JULIAN DAVID ARIAS LONDOÑO",
      "photoUrl": "https://lh4.googleusercontent.com/-QOhj8seXZ4M/AAAAAAAAAAI/AAAAAAAAAKs/jFWlR3Fk460/s64/photo.jpg",
      "userId": "14990390101324121504"
     },
     "user_tz": 300
    },
    "id": "e0-Sf-QxdugV",
    "outputId": "c6ffd2bb-53c8-47ba-f873-96ba2c1cdb7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " \"'\": 3,\n",
       " '(': 4,\n",
       " ')': 5,\n",
       " ',': 6,\n",
       " '-': 7,\n",
       " '.': 8,\n",
       " '0': 9,\n",
       " '1': 10,\n",
       " '2': 11,\n",
       " '3': 12,\n",
       " '4': 13,\n",
       " '5': 14,\n",
       " '6': 15,\n",
       " '7': 16,\n",
       " '8': 17,\n",
       " '9': 18,\n",
       " ':': 19,\n",
       " ';': 20,\n",
       " '?': 21,\n",
       " 'A': 22,\n",
       " 'B': 23,\n",
       " 'C': 24,\n",
       " 'D': 25,\n",
       " 'E': 26,\n",
       " 'F': 27,\n",
       " 'G': 28,\n",
       " 'H': 29,\n",
       " 'I': 30,\n",
       " 'J': 31,\n",
       " 'K': 32,\n",
       " 'L': 33,\n",
       " 'M': 34,\n",
       " 'N': 35,\n",
       " 'O': 36,\n",
       " 'P': 37,\n",
       " 'Q': 38,\n",
       " 'R': 39,\n",
       " 'S': 40,\n",
       " 'T': 41,\n",
       " 'U': 42,\n",
       " 'V': 43,\n",
       " 'W': 44,\n",
       " 'Y': 45,\n",
       " 'Z': 46,\n",
       " '[': 47,\n",
       " ']': 48,\n",
       " 'a': 49,\n",
       " 'b': 50,\n",
       " 'c': 51,\n",
       " 'd': 52,\n",
       " 'e': 53,\n",
       " 'f': 54,\n",
       " 'g': 55,\n",
       " 'h': 56,\n",
       " 'i': 57,\n",
       " 'j': 58,\n",
       " 'k': 59,\n",
       " 'l': 60,\n",
       " 'm': 61,\n",
       " 'n': 62,\n",
       " 'o': 63,\n",
       " 'p': 64,\n",
       " 'q': 65,\n",
       " 'r': 66,\n",
       " 's': 67,\n",
       " 't': 68,\n",
       " 'u': 69,\n",
       " 'v': 70,\n",
       " 'w': 71,\n",
       " 'x': 72,\n",
       " 'y': 73,\n",
       " 'z': 74}"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1555975740042,
     "user": {
      "displayName": "JULIAN DAVID ARIAS LONDOÑO",
      "photoUrl": "https://lh4.googleusercontent.com/-QOhj8seXZ4M/AAAAAAAAAAI/AAAAAAAAAKs/jFWlR3Fk460/s64/photo.jpg",
      "userId": "14990390101324121504"
     },
     "user_tz": 300
    },
    "id": "E3QmRjcudwAV",
    "outputId": "e47e76f7-1173-47da-bb99-745c3c965ac9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  4332554\n",
      "Total Vocab:  75\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the model we are going to use sequences of 60 characters and because of the data set is too large, we are going to use only the firs 200000 sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1076,
     "status": "ok",
     "timestamp": 1555975743874,
     "user": {
      "displayName": "JULIAN DAVID ARIAS LONDOÑO",
      "photoUrl": "https://lh4.googleusercontent.com/-QOhj8seXZ4M/AAAAAAAAAAI/AAAAAAAAAKs/jFWlR3Fk460/s64/photo.jpg",
      "userId": "14990390101324121504"
     },
     "user_tz": 300
    },
    "id": "PdIXZV0bdyav",
    "outputId": "16d75c9d-0ce4-4016-93ff-21655110c18b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  66647\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 60\n",
    "dataX = []\n",
    "dataY = []\n",
    "n_chars = 200000\n",
    "for i in range(0, n_chars - seq_length, 3):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aB2M7vJHd68-"
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xw2XJ482eASh"
   },
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VnMaAPMeVbYq"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the entire dataset is used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 825
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1106024,
     "status": "ok",
     "timestamp": 1555947067072,
     "user": {
      "displayName": "JULIAN DAVID ARIAS LONDOÑO",
      "photoUrl": "https://lh4.googleusercontent.com/-QOhj8seXZ4M/AAAAAAAAAAI/AAAAAAAAAKs/jFWlR3Fk460/s64/photo.jpg",
      "userId": "14990390101324121504"
     },
     "user_tz": 300
    },
    "id": "tIOTswjieGWA",
    "outputId": "5df072e0-e6a3-4582-ccb6-837293359743"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "199900/199900 [==============================] - 60s 300us/step - loss: 2.7076\n",
      "Epoch 2/20\n",
      "199900/199900 [==============================] - 55s 274us/step - loss: 2.3271\n",
      "Epoch 3/20\n",
      "199900/199900 [==============================] - 55s 276us/step - loss: 2.1656\n",
      "Epoch 4/20\n",
      "199900/199900 [==============================] - 55s 275us/step - loss: 2.0490\n",
      "Epoch 5/20\n",
      "199900/199900 [==============================] - 55s 275us/step - loss: 1.9487\n",
      "Epoch 6/20\n",
      "199900/199900 [==============================] - 55s 275us/step - loss: 1.8654\n",
      "Epoch 7/20\n",
      "199900/199900 [==============================] - 55s 275us/step - loss: 1.7964\n",
      "Epoch 8/20\n",
      "199900/199900 [==============================] - 55s 274us/step - loss: 1.7393\n",
      "Epoch 9/20\n",
      "199900/199900 [==============================] - 55s 275us/step - loss: 1.6897\n",
      "Epoch 10/20\n",
      "199900/199900 [==============================] - 55s 275us/step - loss: 1.6484\n",
      "Epoch 11/20\n",
      "199900/199900 [==============================] - 55s 276us/step - loss: 1.6084\n",
      "Epoch 12/20\n",
      "199900/199900 [==============================] - 55s 275us/step - loss: 1.5745\n",
      "Epoch 13/20\n",
      "199900/199900 [==============================] - 55s 275us/step - loss: 1.5429\n",
      "Epoch 14/20\n",
      "199900/199900 [==============================] - 55s 275us/step - loss: 1.5130\n",
      "Epoch 15/20\n",
      "199900/199900 [==============================] - 55s 274us/step - loss: 1.4864\n",
      "Epoch 16/20\n",
      "199900/199900 [==============================] - 55s 275us/step - loss: 1.4617\n",
      "Epoch 17/20\n",
      "199900/199900 [==============================] - 55s 275us/step - loss: 1.4412\n",
      "Epoch 18/20\n",
      "199900/199900 [==============================] - 55s 275us/step - loss: 1.4199\n",
      "Epoch 19/20\n",
      "199900/199900 [==============================] - 55s 274us/step - loss: 1.3984\n",
      "Epoch 20/20\n",
      "199900/199900 [==============================] - 55s 275us/step - loss: 1.3785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdc1311c6a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qMekNHKIeOvl"
   },
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4422,
     "status": "ok",
     "timestamp": 1555947905172,
     "user": {
      "displayName": "JULIAN DAVID ARIAS LONDOÑO",
      "photoUrl": "https://lh4.googleusercontent.com/-QOhj8seXZ4M/AAAAAAAAAAI/AAAAAAAAAKs/jFWlR3Fk460/s64/photo.jpg",
      "userId": "14990390101324121504"
     },
     "user_tz": 300
    },
    "id": "YDxojdGrt_HJ",
    "outputId": "7f6d35e7-85bc-4a1d-ab28-f764efc87625"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" e of\n",
      "Nahor, Abraham's brother, with her pitcher upon her shoulder.\n",
      "\n",
      "24:16 And the damsel was very fa \"\n",
      "ther of the farth after his kind, and the cartle of the cartle of the cartl of the garder.\n",
      "\n",
      "11:12 And the sons of Ioseph were the caughters of Earah, and the Hirites, and the Hiriites, and the Hiriithses, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriithsis, and the Hiriith\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The result is not what we expected mainly because of three resons:\n",
    "\n",
    "- The model requires to be trained with a larger dataset in order to better capture the dynamics of the language.\n",
    "- During validation it is not recommendable to select the output with maximum probability but to use the output distribution as parameters to sample from a multinomial distribution. This avoid the model to get stuck in a loop.\n",
    "- A more flexible model with more data could get better results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R_fcPxZ0Ysqq"
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MRer0n2iV25k"
   },
   "source": [
    "## Using a more complex model with the whole dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem is complex computationally speaking, so the next model was run using GPU. The LSTM layers were replaced by CuDNNLSTM that are suitable to GPU training. These layers were removed in the new alpha version of tensor flow to improve compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BoJ24gB1eC23"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(CuDNNLSTM(256, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(CuDNNLSTM(256))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More data could produce memory erros so we have to create a data_generator function for the problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qZQ6cWqt389J"
   },
   "outputs": [],
   "source": [
    "class KerasBatchGenerator(object):\n",
    "\n",
    "    def __init__(self, data, num_steps, batch_size, vocabulary, skip_step=1):\n",
    "        self.data = data\n",
    "        self.num_steps = num_steps\n",
    "        self.batch_size = batch_size\n",
    "        self.vocabulary = vocabulary\n",
    "        # this will track the progress of the batches sequentially through the\n",
    "        # data set - once the data reaches the end of the data set it will reset\n",
    "        # back to zero\n",
    "        self.current_idx = 0\n",
    "        # skip_step is the number of words which will be skipped before the next\n",
    "        # batch is skimmed from the data set\n",
    "        self.skip_step = skip_step\n",
    "        \n",
    "    def generate(self):\n",
    "        x = np.zeros((self.batch_size, self.num_steps, 1))\n",
    "        y = np.zeros((self.batch_size, self.vocabulary))\n",
    "        while True:\n",
    "            for i in range(self.batch_size):\n",
    "                if self.current_idx + self.num_steps >= len(self.data):\n",
    "                    # reset the index back to the start of the data set\n",
    "                    self.current_idx = 0\n",
    "                seq_in = self.data[self.current_idx:self.current_idx + self.num_steps]\n",
    "                x[i, :, 0] = np.array([char_to_int[char] for char in seq_in])/ float(n_vocab)\n",
    "                seq_out = self.data[self.current_idx + self.num_steps]\n",
    "                temp_y = char_to_int[seq_out]\n",
    "                # convert all of temp_y into a one hot representation\n",
    "                y[i, :] = np_utils.to_categorical(temp_y, num_classes=self.vocabulary)\n",
    "                self.current_idx += self.skip_step\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mYDrqTnX3-ma"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_data_generator = KerasBatchGenerator(raw_text, seq_length, batch_size, n_vocab, skip_step=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1137
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1034414,
     "status": "ok",
     "timestamp": 1555974566404,
     "user": {
      "displayName": "JULIAN DAVID ARIAS LONDOÑO",
      "photoUrl": "https://lh4.googleusercontent.com/-QOhj8seXZ4M/AAAAAAAAAAI/AAAAAAAAAKs/jFWlR3Fk460/s64/photo.jpg",
      "userId": "14990390101324121504"
     },
     "user_tz": 300
    },
    "id": "SHuCgh4_uDYY",
    "outputId": "12d7c041-da3e-4bb0-e5e9-2d7f7bcffa12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1563/1562 [==============================] - 36s 23ms/step - loss: 2.7893\n",
      "Epoch 2/30\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 2.4497\n",
      "Epoch 3/30\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.3598\n",
      "Epoch 4/30\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.2316\n",
      "Epoch 5/30\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.2325\n",
      "Epoch 6/30\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.1817\n",
      "Epoch 7/30\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 1.9401\n",
      "Epoch 8/30\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 1.9399\n",
      "Epoch 9/30\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 1.9131\n",
      "Epoch 10/30\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 1.9930\n",
      "Epoch 11/30\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 1.8264\n",
      "Epoch 12/30\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 1.8750\n",
      "Epoch 13/30\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 1.9305\n",
      "Epoch 14/30\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 1.6937\n",
      "Epoch 15/30\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 1.6999\n",
      "Epoch 16/30\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 1.6825\n",
      "Epoch 17/30\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 1.8233\n",
      "Epoch 18/30\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 1.6562\n",
      "Epoch 19/30\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 1.7292\n",
      "Epoch 20/30\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 1.8125\n",
      "Epoch 21/30\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 1.5995\n",
      "Epoch 22/30\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 1.5741\n",
      "Epoch 23/30\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 1.5898\n",
      "Epoch 24/30\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 1.6875\n",
      "Epoch 25/30\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 1.6150\n",
      "Epoch 26/30\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 1.6054\n",
      "Epoch 27/30\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 1.7184\n",
      "Epoch 28/30\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 1.5911\n",
      "Epoch 29/30\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 1.4848\n",
      "Epoch 30/30\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 1.5300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdbaa8a2c88>"
      ]
     },
     "execution_count": 102,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_data_generator.generate(), epochs=30, steps_per_epoch=n_chars/batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in previous classes, the model trained using batch_input_shape requires a similar batch for validation, so in order to evaluate the model using a single sequence, we have to create a new model with a batch_size = 1 and pass on the learnt weights of the first model to the new one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U92_XqnRibev"
   },
   "outputs": [],
   "source": [
    "# re-define the batch size\n",
    "n_batch = 1\n",
    "# re-define model\n",
    "new_model = Sequential()\n",
    "new_model.add(CuDNNLSTM(256, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), return_sequences=True))\n",
    "new_model.add(Dropout(rate=0.2))\n",
    "new_model.add(CuDNNLSTM(256))\n",
    "new_model.add(Dropout(rate=0.2))\n",
    "new_model.add(Dense(y.shape[1], activation='softmax'))\n",
    "# copy weights\n",
    "old_weights = model.get_weights()\n",
    "new_model.set_weights(old_weights)\n",
    "# compile model\n",
    "new_model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4818,
     "status": "ok",
     "timestamp": 1555974762187,
     "user": {
      "displayName": "JULIAN DAVID ARIAS LONDOÑO",
      "photoUrl": "https://lh4.googleusercontent.com/-QOhj8seXZ4M/AAAAAAAAAAI/AAAAAAAAAKs/jFWlR3Fk460/s64/photo.jpg",
      "userId": "14990390101324121504"
     },
     "user_tz": 300
    },
    "id": "Lodj51rr7KB8",
    "outputId": "3e59171c-45c4-468f-f5df-ce833c993fa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" saidst unto thy servants, Bring him down unto me, that\n",
      "I may \"\n",
      " be the LORD God of Israel, and the sons of Iesashah, and the sons of Merarn, and Serhanhah the son of Sabaah, and Hazidi, and Aaiashah, and Mamariah, and Mehaiiah, and Merhan, and Jamar, and Aanahah, and Jarianah, and Mehaniah, and Aaelarh the son of Jeshan, and Jamarseh, and Jararh.\n",
      "\n",
      "1:15 And the LORD said unto him, Mhere the LORD had said, The LORD had sheer bootier and word the LORD, and all the cre of the LORD the LORD his sons of Gsrael the sons of Ashaha, and the sons of Saul his son, and Saul his son, and the sons of Bavid the son of Marahah, and Jerhahah, and Aaelah, and Eavid the son of Merhaniah, and Maaaiah, and Aavid she was nut of the LORD.\n",
      "\n",
      "15:15 And the sons of Eoshan the son of Dshah, and Sehoahah, and Semladah, and Jaraiah, and Jarars, and Samahah iis son, and Jarahah, and Mamai, and Samah, and Aaiarhah, and Zeulieah, and Aavid was all the camp of the cork of the LORD, and the bhildren of Israel, and the srnnd of the LORD, and the sons of the LORD, and the children of\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, seq_length, 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = new_model.predict(x, verbose=0)[0]\n",
    "    index = sample(prediction, 0.3)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1404,
     "status": "ok",
     "timestamp": 1555975635504,
     "user": {
      "displayName": "JULIAN DAVID ARIAS LONDOÑO",
      "photoUrl": "https://lh4.googleusercontent.com/-QOhj8seXZ4M/AAAAAAAAAAI/AAAAAAAAAKs/jFWlR3Fk460/s64/photo.jpg",
      "userId": "14990390101324121504"
     },
     "user_tz": 300
    },
    "id": "vR9a_xKFiJ2a",
    "outputId": "4175aea9-4942-479c-adde-cfd647cdedd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = new_model.to_json()\n",
    "with open(\"modelgenCuDNNLSTM.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "new_model.save_weights(\"modelgenCuDNNLSTM.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HeZJho6ytwxd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Textgeneration.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
